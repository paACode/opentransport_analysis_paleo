---
title: "Paleo an opentransport Analysis"
author: "Leo Dost and Pascal Ackermann"
date: "30.01.2025"
output: html_document
---

```{r, echo=FALSE , include=FALSE}
## we remove the printing of the hashes in front of all results
library(knitr)
opts_chunk$set(echo = FALSE ,
               include = FALSE,
               comment = NA)
```

# Introduction

MadeUpCompany AG has recently identified that production employees frequently arrive late to work due to delays in public transportation. This poses a significant challenge since the absence of a single team member can halt the entire production line.

To address this issue, the Production Manager has initiated a research project in collaboration with HSLU.

Three possible countermeasure were identified:

- Adjust shift start times based on transportation reliability.
- Implement seasonal adjustments to production capacity based on weather-related transportation disruptions.
- Consider regional hiring preferences to mitigate dependency on unreliable train routes.

The goal of the Data Science students is to provide MadeUpCompany AG with an insightful report, analyzing publicly available data.


# Exploring Data

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.

## Tranport Data

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.

### Data Preprocessing

```{r}
# Histogram: Overview
# 
```

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.

## Weather Data

```{r}
# Histogram: Overview
# 
```

The Federal Office of Meteorology and Climatology MeteoSwiss publishes a wide range of data, including the dataset *Schweizer Klimamessnetz*. This dataset contains the most climatologically significant ground-based measurement stations within MeteoSwiss's measurement network. It consists of 29 climate stations and 46 precipitation stations and includes daily average values of, for example, total snow depth, sunshine duration, precipitation, and air temperature.

### Data Preprocessing

The measurement data from *Schweizer Klimamessnetz* is available in separate CSV files for each station and day. To maintain manageable complexity for analysis within the scope of this module, all measurement values from the 29 different measurement stations were aggregated, and an average value per measurement unit per day was calculated. This preprocessing was performed using a Python script.

``` python
import pandas as pd
import glob
import numpy as np

# Step 1: Define file paths
input_folder = "/Users/leonarddost/Documents/RBootcamp/raw_data"
output_file = "/Users/leonarddost/Documents/RBootcamp/swiss_avg_weather_2024.csv"

# Step 2: Load all CSV files with the correct delimiter
file_paths = glob.glob(f"{input_folder}/*.csv")
dfs = [pd.read_csv(file, delimiter=';') for file in file_paths]

# Step 3: Concatenate the data
combined_df = pd.concat(dfs, ignore_index=True)

# Debugging: Check the columns in the combined DataFrame
print("Column names in the combined DataFrame:", combined_df.columns)

# Step 4: Replace missing values ("-") with NaN
combined_df.replace("-", np.nan, inplace=True)

# Step 5: Convert numeric columns to numeric types (coerce invalid values to NaN)
columns_to_aggregate = [col for col in combined_df.columns if col not in ['station/location', 'date']]

for col in columns_to_aggregate:
    combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')

# Debugging: Print rows with NaN values to check for invalid data
invalid_rows = combined_df[combined_df[columns_to_aggregate].isnull().any(axis=1)]
if not invalid_rows.empty:
    print("Rows with invalid numeric data detected:")
    print(invalid_rows)

# Step 6: Group by 'date' and calculate averages for numeric columns
avg_df = combined_df.groupby('date')[columns_to_aggregate].mean().reset_index()

# Step 7: Rename the columns
column_mapping = {
    'station/location': 'Wetterstation',
    'date': 'Datum',
    'gre000d0': 'Globalstrahlung',
    'hto000d0': 'Gesamtschneehöhe',
    'nto000d0': 'Gesamtbewölkung',
    'prestad0': 'Luftdruck',
    'rre150d0': 'Niederschlag',
    'sre000d0': 'Sonnenscheindauer',
    'tre200d0': 'Lufttemperatur',
    'tre200dn': 'Lufttemperatur (min)',
    'tre200dx': 'Lufttemperatur (max)',
    'ure200d0': 'Luftfeuchtigkeit'
}

avg_df.rename(columns=column_mapping, inplace=True)

# Step 8: Export the final DataFrame to CSV
avg_df.to_csv(output_file, index=False)

print(f"The merged file with updated column names has been saved to: {output_file}")
```

In addition to merging and averaging the individual measurement values, the dataset's labels were also renamed for readability. For example, *tre200d0* was renamed to *Lufttemperatur*.

Finally, we obtained an average weather dataset for Switzerland for the year 2024, based on the most important ground measurement stations within the MeteoSwiss network.

# Data Analysis

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.

# Results

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.

# Conclusion

Lorem ipsum dolor sit amet, consetetur sadipscing elitr, sed diam nonumy eirmod tempor invidunt ut labore et dolore magna aliquyam erat, sed diam voluptua.
